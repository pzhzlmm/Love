# 20-04-13

# HDFS客户端操作-HDFS客户端环境准备

1．找到资料目录下的Windows依赖目录，打开：

![img](20-04-13.assets/1586308204657-360bad0c-dc90-4a6f-9584-a4207bfd0e0f.png)

图3-1 windows依赖

​       选择Hadoop-3.1.0，拷贝到其他地方(比如E:\hadoop\)。

​     ![img](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/1586308204779-49a905d6-3740-4b4a-a985-ba1fe2ae554e.png)

![image-20200413090435629](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413090435629.png)

win本地库

![image-20200413090543203](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413090543203.png)

图3-2 windows依赖存放

2．配置HADOOP_HOME环境变量，如图3-3所示。

![image-20200413090629240](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413090629240.png)

图3-3 配置HADOOP_HOME环境变量

\3. 配置Path环境变量，如图3-4所示。然后重启电脑

![image-20200413090742688](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413090742688.png)

图3-4 配置Path环境变量

把hadoop.dll拷贝到system32目录下

![image-20200413090924898](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413090924898.png)

4．创建一个Maven工程

5．导入相应的依赖坐标+日志添加

```xml
<dependencies>
    <dependency>
        <groupId>junit</groupId>
        <artifactId>junit</artifactId>
        <version>4.12</version>
    </dependency>
    <dependency>
        <groupId>org.apache.logging.log4j</groupId>
        <artifactId>log4j-slf4j-impl</artifactId>
        <version>2.12.0</version>
    </dependency>
    <dependency>
        <groupId>org.apache.hadoop</groupId>
        <artifactId>hadoop-client</artifactId>
        <version>3.1.3</version>
    </dependency>
</dependencies>
```

或者hadoop-client也可写成:

![image-20200413091720906](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413091720906.png)

在项目的src/main /resources目录下，新建一个文件，命名为“log4j2.xml”，在文件中填入

```xml
<?xml version="1.0" encoding="UTF-8"?>
<Configuration status="error" strict="true" name="XMLConfig">
    <Appenders>
        <!-- 类型名为Console，名称为必须属性 -->
        <Appender type="Console" name="STDOUT">
            <!-- 布局为PatternLayout的方式，
            输出样式为[INFO] [2018-01-22 17:34:01][org.test.Console]I'm here -->
            <Layout type="PatternLayout"
                    pattern="[%p] [%d{yyyy-MM-dd HH:mm:ss}][%c{10}]%m%n" />
        </Appender>

    </Appenders>

    <Loggers>
        <!-- 可加性为false -->
        <Logger name="test" level="info" additivity="false">
            <AppenderRef ref="STDOUT" />
        </Logger>

        <!-- root loggerConfig设置 -->
        <Root level="info">
            <AppenderRef ref="STDOUT" />
        </Root>
    </Loggers>

</Configuration>
```

![image-20200413092143848](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413092143848.png)

6．创建包名：com.atguigu.hdfs

7．创建HdfsClient类

注意导包:

![image-20200413092400623](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413092400623.png)

![image-20200413092426471](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413092426471.png)

```java
public class HdfsClient{	
   @Test
    public void testHdfsClient() throws IOException, InterruptedException {
        //1. 创建HDFS客户端对象,传入uri， configuration , user
        FileSystem fileSystem =
                FileSystem.get(URI.create("hdfs://hadoop102:9820"), new Configuration(), "atguigu");
        //2. 操作集群
        // 例如：在集群的/目录下创建 testHDFS目录
        fileSystem.mkdirs(new Path("/testHDFS"));
        //3. 关闭资源
        fileSystem.close();
    }
}
```

8．执行程序

## HDFS的客户端API操作-文件上传

### 编写代码

```java
@Test
    public void testUpload() throws IOException, InterruptedException {
        //1.获取客户端对象
        URI uri = URI.create("hdfs://hadoop102:9820");
        Configuration conf = new Configuration();//配置对象
        conf.set("dfs.replication","1");
        String user = "atguigu";//谁去操作
        //uri:定位资源,指定HDFS集群的位置,即找到namenode就找到集群了
        FileSystem fileSystem = FileSystem.get(uri, conf, user);
        //2.
        fileSystem.copyFromLocalFile(false,true,
                new Path("D:/temp/hadoop/hello.txt"),
                new Path("/testjava"));
    }
```

### 设置外部配置文件

在项目的resources中新建hdfs-site.xml文件，并将如下内容拷贝进去，再次测试

```xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
	<property>
		<name>dfs.replication</name>
        <value>1</value>
	</property>
</configuration>
```

![image-20200413094848742](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413094848742.png)

![image-20200413094719581](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413094719581.png)

### 设置代码内部配置

代码中的conf优先级最高客户端优先级比集群优先级高:defualt-site-客户端-代码中的configuration

![image-20200413095023701](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413095023701.png)

### 小结:参数优先级

参数优先级排序：（1）客户端代码中设置的值 >（2）ClassPath下的用户自定义配置文件 >（3）然后是服务器的自定义配置(xxx-site.xml) >（4）服务器的默认配置(xxx-default.xml)

## HDFS的客户端API操作-文件下载

### 代码编写

```java
    private FileSystem fs;
    //@Before:在所有的测试方法之前会执行这个方法
    @Before
    public void before() throws IOException, InterruptedException {
        URI uri = URI.create("hdfs://hadoop102:9820");
        Configuration conf = new Configuration();
        String user = "atguigu";
        fs = FileSystem.get(uri,conf,user);
    }

    //@After:在所有的测试方法之后会执行这个方法
    @After
    public void after() throws IOException {
        fs.close();
    }
    /**
     * description: testDowload
     * 文件的下载
     * version: 1.0
     * date: 2020/4/13 10:17
     * author: XinLan Wang
     *
     * @param
     * @return void
     */
    @Test
    public void testDowload() throws IOException {
        //参数提示:ctrl + p
        fs.copyToLocalFile(false,
                new Path("/testjava"),
                new Path("D:/temp/hadoop/ss.txt"),//可以明确指定一个名字
                true);//是否开启文件校验
    }
```

### 文件校验API

是否开启文件校验:true代表不要,false代表需要

![image-20200413102722097](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413102722097.png)

如果关闭即开启了文件校验,多出了

![image-20200413102802545](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413102802545.png)

crc是对ss.txt的校验文件,确保这个文件是否正常

### 删除文件

![image-20200413103121897](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413103121897.png)

如果是空目录,或者是具体的文件可以直接删除,无所谓设置true或者false,

但如果是非空目录,如果删除,必须设置为true即可以删除成功

![image-20200413103630451](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413103630451.png)

```java
private FileSystem fs;
    //@Before:在所有的测试方法之前会执行这个方法
    @Before
    public void before() throws IOException, InterruptedException {
        URI uri = URI.create("hdfs://hadoop102:9820");
        Configuration conf = new Configuration();
        String user = "atguigu";
        fs = FileSystem.get(uri,conf,user);
    }

    //@After:在所有的测试方法之后会执行这个方法
    @After
    public void after() throws IOException {
        fs.close();
    }

    /**
     * description: testDelete
     * 删除文件
     * version: 1.0
     * date: 2020/4/13 10:30
     * author: XinLan Wang
     *
     * @param
     * @return void
     */
    @Test
    public void testDelete() throws IOException {
        //删除文件
//        fs.delete(new Path("/testjava/hello.txt"),true);
        //给的是文件设的是false会抛出个异常
        fs.delete(new Path("/testjava"),true);
        //给的是文件设的是false会抛出个异常
    }
```

## 文件的更改移动

```java
 /**
     * description: testRename
     * 文件的更名和移动
     * version: 1.0
     * date: 2020/4/13 10:38
     * author: XinLan Wang
     *
     * @param
     * @return void
     */
    @Test
    public void testRename() throws IOException {
        fs.rename(new Path("/testjava2/hello.txt"),new Path("/testjava2/testjava2.txt"));
        //改名并移动
        fs.rename(new Path("/testjava2/testjava2.txt"),new Path("/xinlan.txt"));
    }
```

执行效果:

![image-20200413110035334](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413110035334.png)

![image-20200413110123390](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413110123390.png)

![image-20200413110224694](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413110224694.png)

## 文件获取详情

```java
 /**
     * description: testListFiles
     * 文件详情查看
     * version: 1.0
     * date: 2020/4/13 10:43
     * author: XinLan Wang
     *
     * @param
     * @return void
     */
    @Test
    public void testListFiles() throws IOException {
        RemoteIterator<LocatedFileStatus> listFiles = fs.listFiles(new Path("/"),true);
        while (listFiles.hasNext()){
            LocatedFileStatus next = listFiles.next();
            //打印每个文件的详情
            System.out.println(next.getPermission() + "\t" +
                    next.getOwner() + "\t" +
                    next.getGroup() + "\t" +
                    next.getLen() + "\t" +
                    next.getReplication() + "\t" +
                    next.getBlockSize() + "\t" +
                    next.getPath().getName());

            BlockLocation[] blockLocations = next.getBlockLocations();
            System.out.println(Arrays.toString(blockLocations));
            System.out.println("--------------------------");
        }

    }
```

效果演示:

![image-20200413105239646](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413105239646.png)

## 文件和文件夹的判断

```java
/**
     * description: isDirOrFile
     * 判断是文件还是文件夹
     * version: 1.0
     * date: 2020/4/13 10:53
     * author: XinLan Wang
     *
     * @param
     * @return void
     */
    @Test
    public void isDirOrFile() throws IOException {
        FileStatus[] fileStatuses = fs.listStatus(new Path("/"));
        for (FileStatus status : fileStatuses){
            if (status.isDirectory()){
                System.out.println(status.getPath().getName() + "是一个目录");
            }else{
                System.out.println(status.getPath().getName() + "是一个文件");
            }
        }
    }
```

效果演示:

![image-20200413105558733](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413105558733.png)

没有dir,要遍历文件夹下所有文件的递归需要自己来写

```java
//自己写的   
public void readFile(Path path) throws IOException {
        FileStatus[] fileStatuses = fs.listStatus(path);
        for (FileStatus status : fileStatuses){
            if (status.isDirectory()){
                System.out.println(status.getPath().getName() + "是一个目录");
                readFile(status.getPath());
            }else{
                System.out.println(status.getPath().getName() + "是一个文件");
            }
        }
    }
//老师写的
    public void testAllDirAndFile(String path,FileSystem fs) throws IOException {
        FileStatus[] listStatus = fs.listStatus(new Path(path));
        //迭代判断
        for (FileStatus status : listStatus){
            //如果是文件
            if (status.isFile()){
                System.out.println("File==>" + path + "/" + status.getPath().getName());
            }else {
                System.out.println("DIR==>" + status.getPath().toString());
                testAllDirAndFile(status.getPath().toString(),fs);
            }
        }
    }
//测试
    @Test
    public void testReadFile() throws IOException {
        readFile(new Path("/"));//我写的
//        testAllDirAndFile("/",fs);
    }

```

## 基于IO上传文件$$$

![image-20200413112959321](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413112959321.png)

```java
 /**
     * description: testIOUpload
     *
     * version: 1.0
     * date: 2020/4/13 11:30
     * author: XinLan Wang
     *
     * @param
     * @return void
     */
    @Test
    public void testIOUpload() throws IOException {
        //待上传的文件
        String src = "D:/temp/hadoop/hello.txt";
        //目标文件
        String dest = "/hahaha.txt";
        //输入流
        FileInputStream in = new FileInputStream(new File(src));
        //输出流
        FSDataOutputStream out = fs.create(new Path(dest));
        //流的拷贝
        /*int i;
        byte[] buffer = new byte[1024];
        while ((i = in.read(buffer)) != -1){
            out.write(buffer,0,i);
        }

        */
        //$$$1137讲这里的时候断网了
        IOUtils.copyBytes(in,out, ByteArrayManager.Conf);
        //关闭
        /*if (in != null){
            in.close();
        }*/
        IOUtils.closeStream(in);
        IOUtils.closeStream(out);
    }
```

## 基于IO下载文件$$$

### 代码

```java
 @Test
    public void testIODownload() throws IOException {
        //待上传的文件
        String src = "/hahaha.txt";
        //目标文件
        String dest = "D:/temp/hadoop/hello3.txt";
        //输入流
        FSDataInputStream in = fs.open(new Path(src));
        //输出流
        FileOutputStream out = new FileOutputStream(new File(dest));
        //流的拷贝
        
        //$$$1137讲这里的时候断网了
        IOUtils.copyBytes(in,out, conf);
        //关闭
        
        IOUtils.closeStream(in);
        IOUtils.closeStream(out);
    }
```

### 分块下载

不在一起存,但仍然能完整地下载下来

![image-20200413114441615](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413114441615.png)

### 分开读$$$

![image-20200413114714891](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413114714891.png)

第一块代码:

![image-20200413114945437](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413114945437.png)

下载成功,文件大小为128M

第二块代码:

从128M开始往后读,可以用seek去定位流的位置,不控制的前提下默认会读到文件的末尾

$$$没截到图

效果:

![image-20200413115244894](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413115244894.png)

合并查看

把第二块内容追加到第二块的后面即可type 2 >> 1

![image-20200413115407257](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413115407257.png)

追加后改变名字,就是我们原有的文件

![image-20200413115444543](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413115444543.png)

只要字节序列没有被改变,就能被还原原有的文件

# HDFS数据流$$$

140041

一个块一个块来,找一个离客户端最近的节点,三个通道是联系起来的,但是客户端只会和其中一个建立请求,其中一个落盘再往后面进行传输

一个backet由n多个trunk组成,收到后逐层应答,再从应答队列里把这个元素删除,表示应答成功,如果迟迟没有应答回来,再把packet移回去再重新应对

![image-20200413142021972](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413142021972.png)

某个节点故障跟剩下节点建立通道

## 写数据

![Snipaste_2020-04-13_14-39-11](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/Snipaste_2020-04-13_14-39-39.png)

![Snipaste_2020-04-13_14-42-24](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/Snipaste_2020-04-13_14-42-24.png)

机架感知

机架是物理 集群是逻辑

决定副本放到哪几个DN上

![image-20200413144419638](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413144419638.png)

![image-20200413145052930](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413145052930.png)

## 读数据

![Snipaste_2020-04-13_15-16-16](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/Snipaste_2020-04-13_15-16-16.png)

# NameNode和SecondaryNameNode

NameNode:维护元数据,内存常备，定期写入磁盘

考虑到数据可靠性安全性,磁盘稳定,但速度慢

如果考虑到数据的可靠性，安全性，可以把元数据维护到磁盘中。但是对Fs的操作伴随着元数据的操作磁盘的操作效率低如果考虑操作效率高，可以把元数据维护到内存中，但是内存的数据可靠性低

综合考虑,内存和磁盘都维护一份,需要考虑数据磁盘的一致性,还需要改内存也要改磁盘

最终解决方案:内存磁盘都维护,但对元数据 的修改只改内存,在磁盘中增加一个编辑日志文件,只需要记录客户端相应的操作即可,而且只做文件的追加,效率还是比较高的

![Snipaste_2020-04-13_15-28-54](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/Snipaste_2020-04-13_15-28-54.png)

如果一直往编辑日志里追加内容,一段时间后数据会特别大,此时NN故障,重新启动后需要走一遍编辑日志的操作,会耗费大量的时间

我们希望定时的将编辑日志的内容和磁盘上实际的元数据（镜像文件）.生成新的镜像文件.这个过程需要耗费资源,交给NN不合适,就让2NN来做了,2NN就是负责替NN进行编辑日志和镜像文件的合并工作的

## NameNode工作机制

先做编辑日志,再进行修改

会生成一个新的编辑日志,原有的和镜像会加载到内存中,拷贝到2NN进行合并,会生成新的镜像文件,然后再把新的镜像替换给NN旧的

fsimage:元数据文件,仅一个

![image-20200413154409315](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413154409315.png)

编辑日志

![Snipaste_2020-04-13_15-44-05](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/Snipaste_2020-04-13_15-44-05.png)

![Snipaste_2020-04-13_15-48-10](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/Snipaste_2020-04-13_15-48-10.png)

![Snipaste_2020-04-13_15-48-55](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/Snipaste_2020-04-13_15-48-55.png)

相比于NN,2NN没有正在只用的编辑日志

![image-20200413155200505](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413155200505.png)

NN挂了,可以让2NN的镜像拷贝过去,但是正在编辑的日志这个是没有的

查看编辑日志

![image-20200413155421339](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413155421339.png)

相当于做了20个操作

查看要转换为xml

![image-20200413155447978](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413155447978.png)

格式

![image-20200413155504272](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413155504272.png)

查看镜像

![image-20200413155539731](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413155539731.png)

查看编辑日志

![image-20200413155715995](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413155715995.png)

下载到本地

![image-20200413155749465](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413155749465.png)

![image-20200413160005500](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413160005500.png)

维护到NN的元数据

![image-20200413160212222](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413160212222.png)

hdfs根目录

维护名字和id的映射

![image-20200413160640372](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413160640372.png)

维护父子关系(文件目录结构)![Snipaste_2020-04-13_16-06-56](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/Snipaste_2020-04-13_16-06-56.png)

总结：每次 NameNode启动会合并镜像文件和编辑日志，后续集群正常工作期间，都是由2N负责镜像文件和编辑日志的合并实际上我们这么理解：NN内存中的数据=磁盘上最新的镜像文件+正在使用的编辑日志

## CheckPoint时间设置

![image-20200413163159156](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413163159156.png)

![image-20200413163251470](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413163251470.png)

## NameNode故障处理

现在都是HA,高可用了,一个挂了直接换另外一个,就没有所谓的故障处理了

方法一:NN故障了,数据丢失了,就用2NN中的数据拷贝到NN存储数据的目录![Snipaste_2020-04-13_16-36-12](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/Snipaste_2020-04-13_16-36-12.png)

![image-20200413163953571](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413163953571.png)

没有正在使用的日志文件

## 集群安全模式

![Snipaste_2020-04-13_16-46-27](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/Snipaste_2020-04-13_16-46-27-1586767605433.png)

DN会把块信息上传到NN,记录哪一个块在哪一个DN上

![Snipaste_2020-04-13_16-51-24](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/Snipaste_2020-04-13_16-51-24.png)

wait:紧急,一离开安全模式马上做的操作,类似于阻塞的感觉

![image-20200413165610473](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413165610473.png)

离开安全模式

![image-20200413165709700](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200413165709700.png)