# 20-04-08

大量数据的存储计算

# Hadoop组成（面试重点）

![image-20200408103603157](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200408103603157.png)

为什么要把Yarn单独提出来呢:解耦,可以支持第三方产品,提高计算效率

## HDFS架构概述

HDFS（Hadoop Distributed File System）的架构概述。

![image-20200408105702053](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200408105702053.png)

NN:名称节点,哪个文件存储到了哪个机器上,统筹整体数据的存储.元数据:保存数据信息的数据,即描述真实数据的数据,对HDFS的操作,必然要经过NN

DN:存储的是真实数据

2NN:不是热备,和NN不能等价替换,NN挂了,2NN也不能代替NN,可以抢救一下,可以理解为NN的秘书,辅助NN干活

热备:两个一模一样,但同时只有一个对外提供服务

## YARN架构概述$$$

yarn就是分任务调度和资源调度

![image-20200408112809979](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200408112809979.png)

NodeManager:DN管理单个结点的资源,处理RM给它安排的任务

ResourceManager:Yarn大哥,和客户端交互,整个集群的资源的管理者,要监控NM状态,分配整个集群资源的调度

为每个MR启动一个AM,启动之后就要申请资源,让RM去分配资源,AM管理MR(MapReduce)的任务,根据启动task的多少去找RM去申请,让RM去给它分配资源

(一个AM的Container是可能分配在不同的节点)都是以Container为单位,分配好的资源用一个Container做一个封装(好处:方便管理,不允许其他资源侵占我的地盘)

一个MapReduce任务对应一个ApplicationMaster

## MapReduce架构概述

先分再合,每个人分一部分数据,一起算,然后把算好的结果进行汇总

MapReduce将计算过程分为两个阶段：Map和Reduce

1）Map阶段并行处理输入数据:分

2）Reduce阶段对Map结果进行汇总:合

![image-20200408115452453](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200408115452453.png)



![image-20200408115433495](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200408115433495.png)

## Hadoop架构小结

Hadoop组成：
    HDFS  (存)
    Yarn  (资源管理和调度)
    MapReduce (算)

HDFS的组成:
    NameNode(NN) : 管理真实数据的元数据, 存数据和读数据都要经过NameNode
    DataNode(DN) : 存储真实的数据
    SecondaryNameNode(2NN) :  辅助Namenode工作,不能替换NameNode。

Yarn组成:
    资源: 每台服务器的硬件资源，例如 内存  cpu  磁盘  网络带宽等. 
    ResourceManager(RM): 管理集群中所有的资源(内存，cpu等)(每个DataNode上的资源)
    NodeManager(NM):     管理单个节点的资源(单个DataNode上的资源)
    ApplicationMaster(AM): 每个MapReduce(MR)任务会启动一个MrAppMaster, 负责为MapReduce向ResourceManager申请资源
    Container:  对资源的封装，防止资源别侵占.

    举例:  运行一个MapReduce任务,MapReduce需要启动2个MapTask 和 1个 ReduceTask，也就是总共3个Task
           首先会启动一个MrAppMaster ，需要用到资源，假如2G内存，此时RM会在有资源的NM上分配资源，运行MrAppMaster[此时就有1个container]
       接下来 MrAppMaster 会根据MapReduce的情况， 比如需要总共启动3个Task , MrAppMaster会向RM申请资源，假如一个Task需要1G的内存， RM会在有资源的NM上分配, 来运行Task. 每个Task单独运行，占用1G内存。此时又有3个Container
       需要解释的是 MrAppMaster和所有的Task可以运行在不同的服务器.
       最后当所有的Task都运行完成后， MrAppMaster会想RM注销自己. RM回收资源。

MapReduce的阶段:
	Map阶段:  数据的分
	Reduce阶段: 数据的合

## 大数据技术生态体系

![image-20200408142737565](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200408142737565.png)

离线:对时间层面要求不高

spark:准实时,来了一个批次进行计算,storm:纯实时,来一个算一个,storm要比spark块,要单独给它搭建一套环境,现在用得较少了

MR写着相对会比较啰嗦,facebook基于mr封装了HIVE,写sql转成MR放离线计算里运行

离线任务一般大半夜平台压力不大的时候跑

所有平台关心的数据都在Zookeeper里

推荐系统框架示例:

![image-20200408143545899](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200408143545899.png)



Nginx:决定当前请求到哪个Tomcat,拿到数据后给后台,可能给Flume做数据采集,通过Kafka到flink或者spark做数据计算,放结果数据库里,前台再从分析结果数据库里去拿数据

# Hadoop运行环境搭建（开发重点）

## 虚拟机准备$$$1450

### CentOS7的搭建

详见:https://www.yuque.com/ruicyquan/bu05ox/coa3od

内存4G(数据量小时可略小),硬盘50G

如果是最小化需安装:

```shell
sudo yum install -y epel-release

sudo yum install -y psmisc nc net-tools rsync vim lrzsz ntp libzstd openssl-static tree iotop
```

改IP,主机名,host,关防火墙,修改yum源

### 远程连接

![image-20200408145056108](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200408145056108.png)

创建软件

![image-20200408144915985](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200408144915985.png)

### chown$$$

普通用户在opt默认没有写权限(文件无法上传等)

![image-20200408145653626](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200408145653626.png)

加上-R把子目录的文件们也一并修改

## 装JDK

hadoop 95%的代码是Java写的,tar gz + 配置环境变量

上传jar包到指定位置(software)

![image-20200408151908812](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200408151908812.png)

### 解压

tar -zxvf jdk-8u212-linux-x64.tar.gz -C /opt/module/

![image-20200408152406360](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200408152406360.png)

![image-20200408152428026](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200408152428026.png)

### 配置方法一:自定义环境变量

新建/etc/profile.d/my_env.sh文件:sudo vim /etc/profile.d/my_env.sh

添加如下内容

```shell
\#JAVA_HOME

export JAVA_HOME=/opt/module/jdk1.8.0_212

export PATH=$PATH:$JAVA_HOME/bin
```

把复制的JAVA安装目录拷贝到指定位置

![image-20200408153104832](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200408153104832.png)

注意添加路径的时候不要忘记系统自带的PATH目录,以及linux里隔开是用:而不是像win中使用;

![image-20200408153555128](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200408153555128.png)

使用java -version/javac检测是否安装成功

![image-20200408153613337](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200408153613337-1586333127595.png)

**注意:**

- 系统原来有path目录,写的时候不要忘记把系统原有的PATH目录带过来
- win里隔开用;linux隔开多个环境变量用:
- 使用export提升成全局的,再用source /etc/profile去执行
- export可以写在最后,即前面声明后面一次性全局化,都行,不强求

### 配置方法二:系统环境变量

也可以直接添加到系统环境变量之中,但注意加在末尾

**但注意:**

乱改系统命令可能用不了,需要谨慎,最好是在/etc/profile.d里去创建用户的环境变量文件

![image-20200408152631283](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200408152631283.png)

图形化界面需要卸载了自带的

![image-20200408161901175](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200408161901175.png)

![image-20200408162147681](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200408162147681.png)

主要是怕和以后的hadoop版本相冲突

## 安装Hadoop$$$

拷贝hadoop的路径

![image-20200408153816792](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200408153816792.png)



把路径这些拷贝到对应位置$$$

![image-20200408154502586](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200408154502586.png)

执行检测

![image-20200408154623153](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200408154623153.png)

**小结**

![image-20200408154536921](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200408154536921.png)

使用图形化界面需要卸载自带的openjdk,然后再安装提供好的jdk

## Hadoop的目录结构$$

### bin/sbin:常用命令

![image-20200408154813609](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200408154813609.png)

![image-20200408154858109](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200408154858109.png)

![image-20200408154921969](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200408154921969.png)

win可用,一般不用

start-all 都启动,都关闭

start/stop yarn 开启关闭yarn

### etc:配置文件

配置文件主要是在这里:xxx-site.xml,如yarn-site.xml

影响整个:core-site

### share:hadoop提供的一系列jar包

![image-20200408155243206](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200408155243206.png)

example hadoop官方提供的一些MR程序

## 逛官网

官网:hadoop.apache.org

![image-20200408162533768](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200408162533768.png)

![image-20200408162719908](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200408162719908.png)

![image-20200408162934968](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200408162934968.png)

本地/伪分布/完全分布式

默认非分布式,用于调试

![image-20200408163312787](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200408163312787.png)

官网xml更到本地:

![image-20200408163432701](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200408163432701.png)

执行

![image-20200408163605924](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200408163605924.png)

找能和正则匹配上的数据找出来

再从之中挑选需要匹配的单词

![image-20200408163824800](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200408163824800.png)

grep:jar包下的一个程序

input:输入路径

output:输出路径,这个路径不能用

dfs[a-z.]+ 挑选df开头,az的单词都可以,+代表可以有多个

![image-20200408164200490](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200408164200490.png)

success:代表程序成功,

part-r-00000:结果文件

![image-20200408164328663](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200408164328663.png)

![image-20200408164314439](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200408164314439.png)

![image-20200408164810017](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200408164810017.png)

换文件执行结果

![image-20200408165458047](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200408165458047.png)

## wordcount

单词出现的次数

解析的时候回按空格切开,作为一个单词

![image-20200408165801560](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200408165801560.png)

随便写些单词上次

![image-20200408165657519](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200408165657519.png)

执行对应命令

![image-20200408165951687](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200408165951687.png)

查看结果

![image-20200408170018008](https://sumomoriaty.oss-cn-beijing.aliyuncs.com/image-20200408170018008.png)